{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv(\"C:/Users/myaka/Desktop/Final_Year_project/data/http_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id     user  \\\n",
      "0  {V1D3-W8BL16YA-2594OWGB}  ANC1950   \n",
      "1  {C7A0-F6CK17IX-5508HGRY}  ANC1950   \n",
      "2  {C0X3-I5RZ16GM-1535IAMY}  ANC1950   \n",
      "3  {G8V6-M0CF17SO-9968THHW}  ANC1950   \n",
      "4  {I9A3-Z4JU92SK-7362XXPN}  SAB1954   \n",
      "\n",
      "                                                 url   activity  \\\n",
      "0  http://icio.us/John_Edward_Brownlee_as_Attorne...  WWW Visit   \n",
      "1  http://babycenter.com/Manchester_SmallScale_Ex...  WWW Visit   \n",
      "2  http://babycenter.com/Manchester_SmallScale_Ex...  WWW Visit   \n",
      "3  http://timeanddate.com/Accurate_News_and_Infor...  WWW Visit   \n",
      "4  http://timeanddate.com/Accurate_News_and_Infor...  WWW Visit   \n",
      "\n",
      "                                             content  \n",
      "0  Further consultation with post-production team...  \n",
      "1  These two populations have been observed in ma...  \n",
      "2  These two populations have been observed in ma...  \n",
      "3  Cape sold the US rights to the recently formed...  \n",
      "4  Cape sold the US rights to the recently formed...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             id  anomaly_score\n",
      "0      {V1D3-W8BL16YA-2594OWGB}       5.919534\n",
      "1      {C7A0-F6CK17IX-5508HGRY}       8.004178\n",
      "2      {C0X3-I5RZ16GM-1535IAMY}       8.004178\n",
      "3      {G8V6-M0CF17SO-9968THHW}       9.268736\n",
      "4      {I9A3-Z4JU92SK-7362XXPN}       9.268736\n",
      "...                         ...            ...\n",
      "82845  {W2Q3-B7GC63MJ-6634UVHS}       8.349240\n",
      "82846  {B7H9-X4MZ94CC-5550ZTRH}       9.039051\n",
      "82847  {G4Q4-T2JT18OE-6607LLBJ}       8.679134\n",
      "82848  {J8P0-I8LQ24HE-5414UGGB}       9.050909\n",
      "82849  {O6X2-Z3EQ49YB-1172IOVU}       8.688117\n",
      "\n",
      "[82850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is a Dask DataFrame already loaded\n",
    "# Drop the 'user' column\n",
    "df = df.drop(columns=['user'])\n",
    "\n",
    "# Remove rows where the 'activity' column is NaN\n",
    "df = df.dropna(subset=['activity'])\n",
    "\n",
    "# Extract numeric features from the 'content' and 'url' columns\n",
    "df['content_length'] = df['content'].apply(len, meta=('x', 'f8'))\n",
    "df['url_length'] = df['url'].apply(len, meta=('x', 'f8'))\n",
    "\n",
    "# Compute final dataset before sorting\n",
    "df = df.compute()\n",
    "\n",
    "# Encode activity types\n",
    "encoder = LabelEncoder()\n",
    "df[\"activity_encoded\"] = encoder.fit_transform(df[\"activity\"])\n",
    "\n",
    "\n",
    "\n",
    "# Combine all features into a single DataFrame\n",
    "features = df[['content_length', 'url_length', 'activity_encoded']]\n",
    "\n",
    "# Convert to pandas DataFrame for the next steps (you can perform Dask operations on smaller chunks)\n",
    "\n",
    "\n",
    "# Initialize the anomaly detection model (Isolation Forest)\n",
    "model = IsolationForest(contamination=0.1)  # You can adjust contamination based on the expected anomaly rate\n",
    "\n",
    "# Train the model on the features\n",
    "model.fit(features)\n",
    "\n",
    "# Get anomaly scores (negative scores indicate outliers/anomalies)\n",
    "anomaly_scores = model.decision_function(features)\n",
    "\n",
    "# Normalize the anomaly scores to be between 0 and 10\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "anomaly_scores_normalized = scaler.fit_transform(anomaly_scores.reshape(-1, 1))\n",
    "\n",
    "# Add the anomaly scores to the original dataframe\n",
    "df['anomaly_score'] = anomaly_scores_normalized.flatten()\n",
    "\n",
    "# Output the final dataframe with anomaly scores\n",
    "print(df[['id', 'anomaly_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"anomaly_http.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
